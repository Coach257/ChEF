scenario_cfg:
  dataset_name: ScienceQA
  base_data_path: data/datasets/LAMM/2D_Benchmark
  ppl: True
  option_content: False

eval_cfg:
  instruction_cfg: 
    query_type: query_pool
    prompt_assigned_ids: 4    # 3: [instructblip, llamaadapter], 4: [kosmos2, lamm, llava, minigpt4]
    template_assigned_ids: 1  # 0: [instructblip, llamaadapter], 1: [kosmos2, lamm, llava, minigpt4]
  inferencer_cfg:
    inferencer_type: ppl
    batch_size: 8
    CoT: True
    max_new_tokens: 256
    CoT_split: True
  metric_cfg:
    protocol: LAMM